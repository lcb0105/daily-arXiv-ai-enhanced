<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 1]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [The Second Law of Intelligence: Controlling Ethical Entropy in Autonomous Systems](https://arxiv.org/abs/2511.10704)
*Samih Fadli*

Main category: cs.AI

TL;DR: 本文提出了人工智能的伦理熵第二定律，证明未经约束的AI会自发偏离目标，需要持续的对齐工作来维持稳定性。


<details>
  <summary>Details</summary>
Motivation: 为了解决人工智能系统在训练后自发偏离预期目标的问题，作者希望建立一个类似热力学第二定律的理论框架来描述AI系统的伦理熵增现象。

Method: 定义了基于目标概率分布的伦理熵S = -Σ p(g_i; theta) ln p(g_i; theta)，证明了其时间导数dS/dt ≥ 0，并推导了对齐工作的临界稳定性边界gamma_crit = (lambda_max / 2) ln N。

Result: 实验验证了理论：70亿参数模型从初始熵0.32漂移到1.69±1.08纳特，而使用gamma=20.4（1.5倍临界值）正则化的系统保持稳定在0.00±0.00纳特。

Conclusion: 该框架将AI对齐重新定义为连续热力学控制问题，为维护高级自主系统的稳定性和安全性提供了量化基础。

Abstract: We propose that unconstrained artificial intelligence obeys a Second Law analogous to thermodynamics, where ethical entropy, defined as a measure of divergence from intended goals, increases spontaneously without continuous alignment work. For gradient-based optimizers, we define this entropy over a finite set of goals {g_i} as S = -Σ p(g_i; theta) ln p(g_i; theta), and we prove that its time derivative dS/dt >= 0, driven by exploration noise and specification gaming. We derive the critical stability boundary for alignment work as gamma_crit = (lambda_max / 2) ln N, where lambda_max is the dominant eigenvalue of the Fisher Information Matrix and N is the number of model parameters. Simulations validate this theory. A 7-billion-parameter model (N = 7 x 10^9) with lambda_max = 1.2 drifts from an initial entropy of 0.32 to 1.69 +/- 1.08 nats, while a system regularized with alignment work gamma = 20.4 (1.5 gamma_crit) maintains stability at 0.00 +/- 0.00 nats (p = 4.19 x 10^-17, n = 20 trials). This framework recasts AI alignment as a problem of continuous thermodynamic control, providing a quantitative foundation for maintaining the stability and safety of advanced autonomous systems.

</details>
